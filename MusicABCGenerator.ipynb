{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5217195,"sourceType":"datasetVersion","datasetId":3035172}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nimport re, json, time\nfrom tqdm import tqdm\nimport torch\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_token\")\nlogin(hf_token)\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, token=hf_token)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    token=hf_token\n)\n\ndef describe_melody_local(melody):\n    prompt = f\"\"\"This is a melody written in ABC notation:\n\n{melody}\n\nPlease describe the **mood**, **sound type**, and **rhythm** of this melody using one label from each of the following categories:\n\nMood:\n[happy, sad, emotional, uplifting, tense, melancholy, romantic, angry, calm, dark, energetic, epic, dreamy, nostalgic, hopeful]\n\nSound Type:\n[solo piano, orchestral, synth heavy, synth pads, bass heavy, melodic lead, percussion-driven, guitar-focused]\n\nRhythm:\n[no beat, has steady beat, syncopated, irregular, rhythmic pulse]\n\nRespond in this format:\nMood: <one label>\nSound Type: <one label>\nRhythm: <one label>\n\nAnswer:\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    output = model.generate(\n        **inputs,\n        max_new_tokens=80,\n        temperature=0.7,\n        do_sample=True,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n    if \"Answer:\" in decoded:\n        return decoded.split(\"Answer:\")[-1].strip()\n    return decoded.strip()\n\nwith open(\"/kaggle/input/abc-notation-music-for-rnn/dataabc.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n\ntunes = raw_text.strip().split(\"\\nX:\")\ntunes = [\"X:\" + t if not t.startswith(\"X:\") else t for t in tunes]\n\ndef extract_melody(tune):\n    return \"\\n\".join([\n        line.strip() for line in tune.splitlines()\n        if not re.match(r\"^[A-Z]:\", line.strip())\n    ])\n\nmelody_only = [extract_melody(t) for t in tunes if len(extract_melody(t)) > 100]\n\nlabeled_data = []\n\nfor idx, melody in tqdm(enumerate(melody_only[:1000]), total=1000, desc=\"Labeling 1000 melodies\"):\n\n    try:\n        result = describe_melody_local(melody)\n        label_dict = {\"melody\": melody}\n        for line in result.splitlines():\n            if \":\" in line:\n                key, value = line.split(\":\", 1)\n                label_dict[key.strip().lower().replace(\" \", \"_\")] = value.strip()\n        labeled_data.append(label_dict)\n\n        time.sleep(0.2) \n\n    except Exception as e:\n        print(f\"Error on {idx+1}: {e}\")\n\noutput_path = \"/kaggle/working/full_labeled_abc.json\"\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(labeled_data, f, indent=2)\n\nprint(f\"\\n Saved {len(labeled_data)} labeled melodies to: {output_path}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T16:21:34.889253Z","iopub.execute_input":"2025-04-10T16:21:34.889524Z","iopub.status.idle":"2025-04-10T16:54:19.212429Z","shell.execute_reply.started":"2025-04-10T16:21:34.889502Z","shell.execute_reply":"2025-04-10T16:54:19.211513Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07a32a92daa248f2bbc7de30aae0c220"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"518150502868438f907fbe6377bda6c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60850ec0b511408785ad592457cef8c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1d2578e04242d38ddf72ba9b374273"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3209d39f4fc44ee384c7fde301fde707"}},"metadata":{}},{"name":"stderr","text":"2025-04-10 16:21:53.278759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744302113.541167      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744302113.625117      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547a427e2be94f7b8439b54b951eaacd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc29850d0b7a45a8b5a92db50bb64b03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d210fa2299a54eea886dec9d289eee71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573157869197450db9da2a82e06f6196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7e00741d034e89b78bd7a66f5591f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"045ffd5bb2864c209c9094dd575626a6"}},"metadata":{}},{"name":"stderr","text":"Labeling 1000 melodies: 100%|██████████| 1000/1000 [30:55<00:00,  1.86s/it]","output_type":"stream"},{"name":"stdout","text":"\n✅ Done! Saved 1000 labeled melodies to: /kaggle/working/full_labeled_abc.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/working/full_labeled_abc.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nsamples = []\nfor item in data:\n    if all(k in item for k in (\"mood\", \"sound_type\", \"rhythm\", \"melody\")):\n        prompt = f\"mood: {item['mood']} | sound_type: {item['sound_type']} | rhythm: {item['rhythm']}\"\n        target = item[\"melody\"]\n        samples.append({\"input\": prompt, \"output\": target})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:25:26.844257Z","iopub.execute_input":"2025-04-13T20:25:26.844947Z","iopub.status.idle":"2025-04-13T20:25:26.856078Z","shell.execute_reply.started":"2025-04-13T20:25:26.844913Z","shell.execute_reply":"2025-04-13T20:25:26.855455Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"for sample in samples[:3]:\n    print(\"Prompt:\", sample[\"input\"])\n    print(\"Target ABC:\\n\", sample[\"output\"])\n    print(\"-----\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:25:30.464759Z","iopub.execute_input":"2025-04-13T20:25:30.465438Z","iopub.status.idle":"2025-04-13T20:25:30.469772Z","shell.execute_reply.started":"2025-04-13T20:25:30.465414Z","shell.execute_reply":"2025-04-13T20:25:30.469105Z"}},"outputs":[{"name":"stdout","text":"Prompt: mood: melancholy | sound_type: synth pads | rhythm: has steady beat\nTarget ABC:\n G3-A (Bcd=e) | f4 (g2dB) | ({d}c3-B) G2-E2 | F4 (D2=E^F) |\nG3-A (Bcd=e) | f4 d2-f2 | (g2a2 b2).g2 | {b}(a2g2 f2).d2 |\n(d2{ed}c2) B2B2 | (A2G2 {AG}F2).D2 | (GABc) (d2{ed}c>A) | G2G2 G2z ||\nG | B2c2 (dcAB) | G2G2 G3G | B2d2 (gfdc) | d2g2 (g3ga) |\n(bagf) (gd)d>c | (B2AG) F-D.D2 | (GABc) d2d2 | (bgfd) cA.F2 |\nG2A2 (B2{cB}AG) | A3-G F2-D2 | (GABc) (d2{ed}c>A) | G2G2 G2z2 ||\n\n-----\n\nPrompt: mood: uplifting | sound_type: melodic lead | rhythm: has steady beat\nTarget ABC:\n f-g | a3-b g3-a | f4 e3-d | d3-c A3-B | c4 d3-e |\nd3-c (3(A2G2F2) | G4F2-G2 | A-d3 d3-e | d6 ||\nA2 | d3-e f3-g | a4 a3-g | a3-b a3-f | g4 g3-g |\na3-b a3-g | {e}=f4 e3-c | d3-c A3-G | A6 f-g |\na3-b g3-a | f4 e3-d | d3-c A3-B | c4 d3-e |\nd3-c (3(A2G2F2) | G4 F2-G2 | A-d3 d3-e | d6 ||\n\n-----\n\nPrompt: mood: uplifting | sound_type: melodic lead | rhythm: has steady beat\nTarget ABC:\n B/2-c/2 | d2 d>-c B2 A-B | (GBAG) F2 D-F | (G>AG).F (D>CD).F | G2 G>-A B3 c |\n(d>ed).c B2 A>-B | (GBAG) F2 D-F | (G>AG).F (D>CD).F | G2 G>A G3 ||\nD | GABc d2 d=e | f2 =ed c>AF>>c | d>edc B2 AB | GFD=E F2 B-c |\n(d>ed).c B2 A2 | (GBAG) F2 D-F | (G>AG).F (D>CD).F | G2 G>A G3 ||\n\n-----\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import T5Tokenizer\nfrom datasets import Dataset\n\ndataset = Dataset.from_list(samples)\n\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\nmax_input_len = 128\nmax_target_len = 512\n\ndef preprocess(example):\n    model_input = tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=max_input_len)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(example[\"output\"], padding=\"max_length\", truncation=True, max_length=max_target_len)\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\ntokenized_dataset = dataset.map(preprocess, remove_columns=[\"input\", \"output\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:25:35.909733Z","iopub.execute_input":"2025-04-13T20:25:35.909964Z","iopub.status.idle":"2025-04-13T20:25:45.188460Z","shell.execute_reply.started":"2025-04-13T20:25:35.909949Z","shell.execute_reply":"2025-04-13T20:25:45.187566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"350ad3410f9447a3a2e06e6ce082ef75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a141a12c82ea4fdb8935485640f0470e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f90cc227f1d4e6cb39ab102ac5fd767"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b795a1aae241d291dfbbb146016f7c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, TrainingArguments, Trainer\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/t5_abc_model\",\n    per_device_train_batch_size=4,\n    num_train_epochs=6,\n    logging_steps=100,                \n    save_total_limit=1,\n    save_strategy=\"epoch\",\n    fp16=True,\n    logging_dir=\"/kaggle/working/logs\",  \n    report_to=\"none\",                \n    disable_tqdm=False               \n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:27:29.732776Z","iopub.execute_input":"2025-04-13T20:27:29.733466Z","iopub.status.idle":"2025-04-13T20:32:14.301695Z","shell.execute_reply.started":"2025-04-13T20:27:29.733439Z","shell.execute_reply":"2025-04-13T20:32:14.301112Z"}},"outputs":[{"name":"stderr","text":"2025-04-13 20:27:36.148114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744576056.332411      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744576056.386351      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118158062e2f4859ac122a0ef88a5968"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ab4ff68b2643bcbc04e7fbe983b41a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26f7f880f874483b3c1f4635fbeb8ce"}},"metadata":{}},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='738' max='738' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [738/738 04:21, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>3.041600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.289700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.141200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.020700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.003200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.982500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.982600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=738, training_loss=1.3294657730474704, metrics={'train_runtime': 263.9073, 'train_samples_per_second': 22.326, 'train_steps_per_second': 2.796, 'total_flos': 199358473568256.0, 'train_loss': 1.3294657730474704, 'epoch': 6.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/t5_abc_model\")\ntokenizer.save_pretrained(\"/kaggle/working/t5_abc_model\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:08:47.339999Z","iopub.execute_input":"2025-04-10T18:08:47.340299Z","iopub.status.idle":"2025-04-10T18:08:48.022443Z","shell.execute_reply.started":"2025-04-10T18:08:47.340259Z","shell.execute_reply":"2025-04-10T18:08:48.021806Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/t5_abc_model/tokenizer_config.json',\n '/kaggle/working/t5_abc_model/special_tokens_map.json',\n '/kaggle/working/t5_abc_model/spiece.model',\n '/kaggle/working/t5_abc_model/added_tokens.json')"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"from music21 import converter\nfrom IPython.display import Audio\n\ndef abc_to_midi(abc_string, midi_path=\"/kaggle/working/generated.mid\"):\n    if \"K:\" not in abc_string:\n        abc_string = \"X:1\\nT:Generated\\nM:4/4\\nK:C\\n\" + abc_string\n\n    try:\n        score = converter.parse(abc_string, format='abc')\n        score.write('midi', fp=midi_path)\n        return midi_path\n    except Exception as e:\n        print(\"Failed:\", e)\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:43:30.298988Z","iopub.execute_input":"2025-04-13T20:43:30.299298Z","iopub.status.idle":"2025-04-13T20:43:30.304005Z","shell.execute_reply.started":"2025-04-13T20:43:30.299279Z","shell.execute_reply":"2025-04-13T20:43:30.303235Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def standardize_abc(abc):\n    abc = abc.strip()\n    if \"K:\" not in abc:\n        abc = \"K:C\\n\" + abc\n    if \"M:\" not in abc:\n        abc = \"M:4/4\\n\" + abc\n    if not abc.startswith(\"X:\"):\n        abc = \"X:1\\nT:Generated\\n\" + abc\n    if \"Z:\" not in abc:\n        abc += \"\\nZ:1\" \n    return abc\n\nsamples = []\nfor item in data:\n    if all(k in item for k in (\"mood\", \"sound_type\", \"rhythm\", \"melody\")):\n        melody = standardize_abc(item[\"melody\"])\n        if len(melody.split()) > 20:\n            prompt = f\"mood: {item['mood']} | sound_type: {item['sound_type']} | rhythm: {item['rhythm']}\"\n            samples.append({\"input\": prompt, \"output\": melody})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:26:21.393103Z","iopub.execute_input":"2025-04-13T20:26:21.393575Z","iopub.status.idle":"2025-04-13T20:26:21.404183Z","shell.execute_reply.started":"2025-04-13T20:26:21.393550Z","shell.execute_reply":"2025-04-13T20:26:21.403467Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import T5Tokenizer\n\ndataset = Dataset.from_list(samples)\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\ndef preprocess(example):\n    model_input = tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(example[\"output\"], padding=\"max_length\", truncation=True, max_length=512)\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\ntokenized_dataset = dataset.map(preprocess, remove_columns=[\"input\", \"output\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:26:48.008078Z","iopub.execute_input":"2025-04-13T20:26:48.008330Z","iopub.status.idle":"2025-04-13T20:26:49.394668Z","shell.execute_reply.started":"2025-04-13T20:26:48.008312Z","shell.execute_reply":"2025-04-13T20:26:49.393885Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/982 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdf285cc3d240f19979a7048d561089"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import re\n\ndef is_spam(abc):\n    tokens = abc.split()\n    if tokens.count(\"f2\") > 15:\n        return True\n    if len(set(tokens)) < 6:\n        return True\n    return False\n\ndef clean_abc_output(abc):\n    if \"Z:\" in abc:\n        abc = abc.split(\"Z:\")[0].strip()\n    if \"K:\" in abc:\n        abc = \"K:\" + abc.split(\"K:\")[1]\n    return abc.strip()\n\ndef generate_abc(prompt_text, max_new_tokens=400, retries=3):\n    for _ in range(retries):\n        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            min_length=80,\n            temperature=0.9,\n            top_p=0.95,\n            repetition_penalty=1.7,\n            no_repeat_ngram_size=6,\n            pad_token_id=tokenizer.eos_token_id\n        )\n        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        cleaned = clean_abc_output(result)\n        if not is_spam(cleaned):\n            return cleaned\n    return cleaned  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:27:23.886516Z","iopub.execute_input":"2025-04-13T20:27:23.887159Z","iopub.status.idle":"2025-04-13T20:27:23.893180Z","shell.execute_reply.started":"2025-04-13T20:27:23.887132Z","shell.execute_reply":"2025-04-13T20:27:23.892395Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from music21 import converter\nimport re\n\ndef save_abc_to_midi(abc_string, filename=\"generated.mid\", folder=\"/kaggle/working\"):\n    abc_clean = re.sub(r\"(?m)^[XTMKLZ]:.*$\", \"\", abc_string).strip()\n\n    abc_full = \"X:1\\nT:Generated\\nM:4/4\\nK:C\\n\" + abc_clean + \"\\nZ:1\"\n\n    try:\n        score = converter.parse(abc_full, format='abc')\n        midi_path = f\"{folder}/{filename}\"\n        score.write('midi', fp=midi_path)\n        print(f\"Saved to: {midi_path}\")\n    except Exception as e:\n        print(\"Error:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:33:28.686245Z","iopub.execute_input":"2025-04-13T20:33:28.686809Z","iopub.status.idle":"2025-04-13T20:33:29.839601Z","shell.execute_reply.started":"2025-04-13T20:33:28.686788Z","shell.execute_reply":"2025-04-13T20:33:29.839026Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"abc = generate_abc(\"mood: melancholic | sound_type: melodic lead | rhythm: no beat\")\nsave_abc_to_midi(abc, filename=\"dreamy_piano.mid\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:43:34.825596Z","iopub.execute_input":"2025-04-13T20:43:34.826094Z","iopub.status.idle":"2025-04-13T20:43:39.173092Z","shell.execute_reply.started":"2025-04-13T20:43:34.826070Z","shell.execute_reply":"2025-04-13T20:43:39.172386Z"}},"outputs":[{"name":"stdout","text":"✅ Saved to: /kaggle/working/dreamy_piano1.mid\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}